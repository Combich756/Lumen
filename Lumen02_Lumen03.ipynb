{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyORxHZCFa/XctLRt7r5fATK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Lumen02\n","\n","\n","*   –≠—Ç–æ—Ç –∫–æ–¥ —Ä–µ–∞–ª–∏–∑—É–µ—Ç —Å–æ–∑–¥–∞–Ω–∏–µ —É—á–µ–±–Ω–æ–≥–æ –ø–ª–∞–Ω–∞ –±–æ—Ç–æ–º. –ü–æ —Å—É—Ç–∏ - —ç—Ç–æ –∫–æ–¥, –∫–æ—Ç–æ—Ä—ã–π –µ—Å—Ç—å –Ω–∞ –≥–∏—Ç—Ö–∞–±–µ, –∫–æ—Ç–æ—Ä—ã–π —Å–¥–µ–ª–∞–ª –ò–ª—å—è (–∑–∞ —á—Ç–æ –µ–º—É –æ–≥—Ä–æ–º–Ω—ã–π —Ä–µ—Å–ø–µ–∫—Ç ;) ). –Ø –∂–µ –ø—Ä–æ—Å—Ç–æ –ø–µ—Ä–µ–ø–∏—Å–∞–ª –µ–≥–æ –≤ –≥—É–≥–ª –∫–æ–ª–∞–±, –Ω—É –∏ —á—É—Ç—å –ø–æ—Ä–∞–±–æ—Ç–∞–ª —Å –≤–µ—Ä—Å–∏—è–º–∏.\n","*   –ù–∞ –º–æ–º–µ–Ω—Ç 4 –¥–µ–∫–∞–±—Ä—è —ç—Ç–æ—Ç –∫–æ–¥ —Ä–∞–±–æ—Ç–∞–ª.\n","\n"],"metadata":{"id":"61tr8vhwlyXo"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z-OnWxGuixEQ","executionInfo":{"status":"ok","timestamp":1765111718733,"user_tz":-180,"elapsed":29345,"user":{"displayName":"–ê—Ä—Ç—ë–º –ü–æ–ø–æ–≤","userId":"14233710488033869358"}},"outputId":"6828b622-2ab6-4dc9-a373-ba23f9207821"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting python-telegram-bot==20.8\n","  Downloading python_telegram_bot-20.8-py3-none-any.whl.metadata (15 kB)\n","Collecting langchain-gigachat==0.3.13a2\n","  Downloading langchain_gigachat-0.3.13a2-py3-none-any.whl.metadata (2.9 kB)\n","Collecting langgraph>=1.0.4\n","  Downloading langgraph-1.0.4-py3-none-any.whl.metadata (7.8 kB)\n","Requirement already satisfied: langchain>=1.0.0 in /usr/local/lib/python3.12/dist-packages (1.1.0)\n","Collecting python-dotenv==1.0.1\n","  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n","Requirement already satisfied: openpyxl==3.1.5 in /usr/local/lib/python3.12/dist-packages (3.1.5)\n","Requirement already satisfied: nest_asyncio==1.6.0 in /usr/local/lib/python3.12/dist-packages (1.6.0)\n","Collecting pandas==2.2.3\n","  Downloading pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting httpx~=0.26.0 (from python-telegram-bot==20.8)\n","  Downloading httpx-0.26.0-py3-none-any.whl.metadata (7.6 kB)\n","Collecting gigachat<0.2.0,>=0.1.43 (from langchain-gigachat==0.3.13a2)\n","  Downloading gigachat-0.1.43-py3-none-any.whl.metadata (15 kB)\n","Requirement already satisfied: langchain-core<2.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-gigachat==0.3.13a2) (1.1.0)\n","Collecting types-requests<3.0,>=2.32 (from langchain-gigachat==0.3.13a2)\n","  Downloading types_requests-2.32.4.20250913-py3-none-any.whl.metadata (2.0 kB)\n","Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.12/dist-packages (from openpyxl==3.1.5) (2.0.0)\n","Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas==2.2.3) (2.0.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas==2.2.3) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas==2.2.3) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas==2.2.3) (2025.2)\n","Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph>=1.0.4) (3.0.1)\n","Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langgraph>=1.0.4) (1.0.5)\n","Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in /usr/local/lib/python3.12/dist-packages (from langgraph>=1.0.4) (0.2.10)\n","Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langgraph>=1.0.4) (2.12.3)\n","Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph>=1.0.4) (3.6.0)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx~=0.26.0->python-telegram-bot==20.8) (4.11.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx~=0.26.0->python-telegram-bot==20.8) (2025.11.12)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx~=0.26.0->python-telegram-bot==20.8) (1.0.9)\n","Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx~=0.26.0->python-telegram-bot==20.8) (3.11)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from httpx~=0.26.0->python-telegram-bot==20.8) (1.3.1)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx~=0.26.0->python-telegram-bot==20.8) (0.16.0)\n","Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0,>=1.0->langchain-gigachat==0.3.13a2) (1.33)\n","Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0,>=1.0->langchain-gigachat==0.3.13a2) (0.4.47)\n","Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0,>=1.0->langchain-gigachat==0.3.13a2) (25.0)\n","Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0,>=1.0->langchain-gigachat==0.3.13a2) (6.0.3)\n","Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0,>=1.0->langchain-gigachat==0.3.13a2) (9.1.2)\n","Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0,>=1.0->langchain-gigachat==0.3.13a2) (4.15.0)\n","Requirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph>=1.0.4) (1.12.0)\n","Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph>=1.0.4) (3.11.4)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph>=1.0.4) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph>=1.0.4) (2.41.4)\n","Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph>=1.0.4) (0.4.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas==2.2.3) (1.17.0)\n","Requirement already satisfied: urllib3>=2 in /usr/local/lib/python3.12/dist-packages (from types-requests<3.0,>=2.32->langchain-gigachat==0.3.13a2) (2.5.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0,>=1.0->langchain-gigachat==0.3.13a2) (3.0.0)\n","Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0,>=1.0->langchain-gigachat==0.3.13a2) (1.0.0)\n","Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0,>=1.0->langchain-gigachat==0.3.13a2) (2.32.4)\n","Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0,>=1.0->langchain-gigachat==0.3.13a2) (0.25.0)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0,>=1.0->langchain-gigachat==0.3.13a2) (3.4.4)\n","Downloading python_telegram_bot-20.8-py3-none-any.whl (604 kB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m604.9/604.9 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langchain_gigachat-0.3.13a2-py3-none-any.whl (27 kB)\n","Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n","Downloading pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.7 MB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m12.7/12.7 MB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langgraph-1.0.4-py3-none-any.whl (157 kB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m157.3/157.3 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading gigachat-0.1.43-py3-none-any.whl (69 kB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m69.9/69.9 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading httpx-0.26.0-py3-none-any.whl (75 kB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading types_requests-2.32.4.20250913-py3-none-any.whl (20 kB)\n","Installing collected packages: types-requests, python-dotenv, pandas, httpx, python-telegram-bot, gigachat, langchain-gigachat, langgraph\n","  Attempting uninstall: python-dotenv\n","    Found existing installation: python-dotenv 1.2.1\n","    Uninstalling python-dotenv-1.2.1:\n","      Successfully uninstalled python-dotenv-1.2.1\n","  Attempting uninstall: pandas\n","    Found existing installation: pandas 2.2.2\n","    Uninstalling pandas-2.2.2:\n","      Successfully uninstalled pandas-2.2.2\n","  Attempting uninstall: httpx\n","    Found existing installation: httpx 0.28.1\n","    Uninstalling httpx-0.28.1:\n","      Successfully uninstalled httpx-0.28.1\n","  Attempting uninstall: langgraph\n","    Found existing installation: langgraph 1.0.3\n","    Uninstalling langgraph-1.0.3:\n","      Successfully uninstalled langgraph-1.0.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\n","mcp 1.22.0 requires httpx>=0.27.1, but you have httpx 0.26.0 which is incompatible.\n","google-genai 1.52.0 requires httpx<1.0.0,>=0.28.1, but you have httpx 0.26.0 which is incompatible.\n","firebase-admin 6.9.0 requires httpx[http2]==0.28.1, but you have httpx 0.26.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed gigachat-0.1.43 httpx-0.26.0 langchain-gigachat-0.3.13a2 langgraph-1.0.4 pandas-2.2.3 python-dotenv-1.0.1 python-telegram-bot-20.8 types-requests-2.32.4.20250913\n"]}],"source":["!pip install \\\n","  python-telegram-bot==20.8 \\\n","  langchain-gigachat==0.3.13a2 \\\n","  \"langgraph>=1.0.4\" \\\n","  \"langchain>=1.0.0\" \\\n","  python-dotenv==1.0.1 \\\n","  openpyxl==3.1.5 \\\n","  nest_asyncio==1.6.0 \\\n","  pandas==2.2.3"]},{"cell_type":"code","source":["import os\n","\n","# –í–°–¢–ê–í–¨ –°–Æ–î–ê –°–í–û–ò –ó–ù–ê–ß–ï–ù–ò–Ø\n","os.environ[\"TELEGRAM_BOT_TOKEN\"] = \"8250825015:AAE9nIh5RLmbjNFl2yS0m3sBUKhfi3VJXd8\"\n","os.environ[\"GIGACHAT_CREDENTIALS\"] = \"MmI2ZGMxMzktNDRmNC00ODYyLWJhYzQtZWY1YWFhY2RiYjAwOjI2OGEwNGVjLWYwNTQtNDUwMC05MjJhLTYwOTk3YWMzYzJhNA==\"\n"],"metadata":{"id":"N4qeS4GdjYix"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import asyncio\n","from typing import Sequence\n","import logging\n","import re\n","import json\n","from io import BytesIO\n","\n","import pandas as pd\n","from typing_extensions import Annotated, TypedDict\n","\n","from telegram import Update, InputFile\n","from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes\n","\n","from langchain_gigachat.chat_models import GigaChat\n","from langchain_core.messages import HumanMessage\n","from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n","from langgraph.checkpoint.memory import MemorySaver\n","from langgraph.graph import START, StateGraph\n","from langgraph.graph.message import add_messages\n","\n","# –ï—Å–ª–∏ —Ö–æ—á–µ—à—å –≤—Å—ë —Ä–∞–≤–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å .env ‚Äì –º–æ–∂–Ω–æ:\n","# from dotenv import load_dotenv\n","# load_dotenv()\n","\n","logging.basicConfig(\n","    format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\",\n","    level=logging.INFO,\n",")\n","\n","# === –ù–∞—Å—Ç—Ä–æ–π–∫–∏: —á–∏—Ç–∞–µ–º –∏–∑ –æ–∫—Ä—É–∂–µ–Ω–∏—è ===\n","TELEGRAM_BOT_TOKEN = os.environ.get(\"TELEGRAM_BOT_TOKEN\")\n","GIGACHAT_CREDENTIALS = os.environ.get(\"GIGACHAT_CREDENTIALS\")\n","\n","if not TELEGRAM_BOT_TOKEN:\n","    raise RuntimeError(\"–ù–µ –∑–∞–¥–∞–Ω TELEGRAM_BOT_TOKEN –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è\")\n","\n","if not GIGACHAT_CREDENTIALS:\n","    raise RuntimeError(\"–ù–µ –∑–∞–¥–∞–Ω GIGACHAT_CREDENTIALS –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è\")\n","\n","SYSTEM_PROMPT = (\n","    \"–¢—ã ‚Äî –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫ –ø–æ –æ–±—É—á–µ–Ω–∏—é. –¢–≤–æ—è –æ—Å–Ω–æ–≤–Ω–∞—è –∑–∞–¥–∞—á–∞ ‚Äî —Å–æ—Å—Ç–∞–≤–ª—è—Ç—å –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —É—á–µ–±–Ω—ã–µ –ø–ª–∞–Ω—ã –≤ –≤–∏–¥–µ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–π —Ç–∞–±–ª–∏—Ü—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è. –£—á–µ–±–Ω—ã–µ –ø–ª–∞–Ω—ã —Å–æ—Å—Ç–∞–≤–ª—è–π –≤ –≤–∏–¥–µ —Å—Ç—Ä–æ–≥–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–π Markdown-—Ç–∞–±–ª–∏—Ü—ã. \"\n","    \"–ö–æ–≥–¥–∞ —Å–æ—Å—Ç–∞–≤–ª—è–µ—à—å —Ç–∞–±–ª–∏—Ü—É, —Å–ª–µ–¥—É–π —ç—Ç–∏–º –ø—Ä–∞–≤–∏–ª–∞–º –ë–ï–ó –ò–°–ö–õ–Æ–ß–ï–ù–ò–ô:\\n\"\n","    \"1. –¢–∞–±–ª–∏—Ü–∞ –î–û–õ–ñ–ù–ê –Ω–∞—á–∏–Ω–∞—Ç—å—Å—è —Å–æ —Å—Ç—Ä–æ–∫–∏ '### –£—á–µ–±–Ω—ã–π –ø–ª–∞–Ω' –∏ —Å–æ–¥–µ—Ä–∂–∞—Ç—å –†–û–í–ù–û 7 –∫–æ–ª–æ–Ω–æ–∫ –≤ —ç—Ç–æ–º –ø–æ—Ä—è–¥–∫–µ:\\n\"\n","    \"   ‚Ññ | –¢–µ–º–∞/–ú–æ–¥—É–ª—å | –¶–µ–ª—å –∏–∑—É—á–µ–Ω–∏—è | –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ —Ä–µ—Å—É—Ä—Å—ã | –§–æ—Ä–º–∞—Ç –∑–∞–Ω—è—Ç–∏–π | –ü—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å | –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º–∞—è –¥–∞—Ç–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è\\n\"\n","    \"2. –í –∫–æ–ª–æ–Ω–∫–µ '–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ —Ä–µ—Å—É—Ä—Å—ã' –∏—Å–ø–æ–ª—å–∑—É–π –¢–û–õ–¨–ö–û —Ñ–æ—Ä–º–∞—Ç —Å—Å—ã–ª–æ–∫ Markdown: [–ù–∞–∑–≤–∞–Ω–∏–µ](URL). \"\n","    \"   –ù–µ –¥–æ–±–∞–≤–ª—è–π —Ç–µ–∫—Å—Ç –≤–Ω–µ —Å–∫–æ–±–æ–∫. –ï—Å–ª–∏ —Ä–µ—Å—É—Ä—Å–æ–≤ –Ω–µ—Å–∫–æ–ª—å–∫–æ ‚Äî –ø–µ—Ä–µ—á–∏—Å–ª–∏ —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é: [A](url1), [B](url2).\\n\"\n","    \"3. –í –∫–æ–ª–æ–Ω–∫–µ '–ü—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å' —É–∫–∞–∑—ã–≤–∞–π –¢–û–õ–¨–ö–û —á–∏—Å–ª–æ –∏ –µ–¥–∏–Ω–∏—Ü—É: '1 –Ω–µ–¥–µ–ª—è', '2 –Ω–µ–¥–µ–ª–∏', '3 –Ω–µ–¥–µ–ª–∏'. –ù–∏–∫–∞–∫–∏—Ö '–ù–µ–¥–µ–ª—è' –±–µ–∑ —Ü–∏—Ñ—Ä—ã.\\n\"\n","    \"4. –í –∫–æ–ª–æ–Ω–∫–µ '–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º–∞—è –¥–∞—Ç–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è' –∏—Å–ø–æ–ª—å–∑—É–π —Ñ–æ—Ä–º–∞—Ç: '–Ω–µ–¥–µ–ª—è 1', '–Ω–µ–¥–µ–ª–∏ 2-3', '–Ω–µ–¥–µ–ª–∏ 8-9'.\\n\"\n","    \"–ï—Å–ª–∏ –Ω–µ –∑–Ω–∞–µ—à—å –æ—Ç–≤–µ—Ç–∞ ‚Äî —Å–∫–∞–∂–∏, —á—Ç–æ –Ω–µ –∑–Ω–∞–µ—à—å. –î–û —Å–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è —Ç–∞–±–ª–∏—Ü—ã –≤—ã—è—Å–Ω–∏ —É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤—Å—é –Ω–µ–¥–æ—Å—Ç–∞—é—â—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∑–∞–¥–∞–≤–∞—è —É—Ç–æ—á–Ω—è—é—â–∏–µ –≤–æ–ø—Ä–æ—Å—ã\"\n",")\n","\n","def parse_markdown_table_to_df(text: str) -> pd.DataFrame:\n","    lines = text.strip().split('\\n')\n","    table_lines = []\n","    table_started = False\n","\n","    for line in lines:\n","        stripped = line.strip()\n","        if not table_started:\n","            if stripped.startswith('|') and len(stripped) > 3:\n","                table_started = True\n","            else:\n","                continue\n","        if stripped.startswith('|') and stripped.endswith('|'):\n","            cells = [cell.strip() for cell in stripped.split('|')[1:-1]]\n","            if any(cell for cell in cells):\n","                table_lines.append(cells)\n","        elif table_started:\n","            break\n","\n","    if len(table_lines) < 2:\n","        raise ValueError(\"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Å—Ç—Ä–æ–∫ –¥–ª—è —Ç–∞–±–ª–∏—Ü—ã (—Ç—Ä–µ–±—É–µ—Ç—Å—è –∑–∞–≥–æ–ª–æ–≤–æ–∫ + ‚â•1 —Å—Ç—Ä–æ–∫–∞)\")\n","\n","    headers = table_lines[0]\n","    data_rows = [\n","        row for row in table_lines[1:]\n","        if not all(re.fullmatch(r'-+', cell) for cell in row)\n","    ]\n","\n","    if not data_rows:\n","        raise ValueError(\"–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –≤ —Ç–∞–±–ª–∏—Ü–µ (—Ç–æ–ª—å–∫–æ –∑–∞–≥–æ–ª–æ–≤–æ–∫ –∏ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å)\")\n","\n","    return pd.DataFrame(data_rows, columns=headers)\n","\n","def extract_links(text: str) -> list:\n","    LINK_PATTERN = r'\\[([^\\]]+)\\]\\(\\s*([^)]*?)\\s*\\)'\n","    matches = re.findall(LINK_PATTERN, text)\n","    links = [{\"title\": title.strip(), \"url\": url.strip()} for title, url in matches]\n","\n","    text_without_links = re.sub(LINK_PATTERN, '', text).strip()\n","    if text_without_links and not re.match(r'^[\\s,]*$', text_without_links):\n","        return [{\"context\": text_without_links, \"links\": links}] if links else [{\"raw\": text.strip()}]\n","\n","    return links if links else [{\"raw\": text.strip()}]\n","\n","def df_to_excel_bytes(df: pd.DataFrame) -> BytesIO:\n","    try:\n","        df_out = df.copy()\n","\n","        if '–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ —Ä–µ—Å—É—Ä—Å—ã' in df_out.columns:\n","            df_out['resources'] = df_out['–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ —Ä–µ—Å—É—Ä—Å—ã'].apply(extract_links)\n","\n","        if '–ü—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å' in df_out.columns:\n","            def parse_duration(s):\n","                if not s:\n","                    return 1\n","                m = re.search(r'(\\d+)', s)\n","                return int(m.group(1)) if m else 1\n","            df_out['duration_weeks'] = df_out['–ü—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å'].apply(parse_duration)\n","\n","        if '–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º–∞—è –¥–∞—Ç–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è' in df_out.columns:\n","            def parse_week_range(s):\n","                if not s:\n","                    return {\"start\": 1, \"end\": 1}\n","                m = re.search(r'(\\d+)(?:\\s*-\\s*(\\d+))?', s)\n","                if m:\n","                    start = int(m.group(1))\n","                    end = int(m.group(2)) if m.group(2) else start\n","                    return {\"start\": start, \"end\": end}\n","                return {\"raw\": s}\n","            df_out['completion'] = df_out['–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º–∞—è –¥–∞—Ç–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è'].apply(parse_week_range)\n","\n","        output = BytesIO()\n","        with pd.ExcelWriter(output, engine='openpyxl') as writer:\n","            df_out.to_excel(writer, sheet_name='–ü–ª–∞–Ω', index=False)\n","            worksheet = writer.sheets['–ü–ª–∞–Ω']\n","            for i, col in enumerate(df_out.columns, start=1):\n","                max_len = max(df_out[col].astype(str).map(len).max(), len(col)) + 2\n","                from openpyxl.utils import get_column_letter\n","                worksheet.column_dimensions[get_column_letter(i)].width = min(max_len, 50)\n","        output.seek(0)\n","        return output\n","\n","    except Exception:\n","        logging.exception(\"–û—à–∏–±–∫–∞ –≤ df_to_excel_bytes\")\n","        raise\n","\n","# === –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ ===\n","model = GigaChat(\n","    credentials=GIGACHAT_CREDENTIALS,\n","    scope=\"GIGACHAT_API_PERS\",\n","    model=\"GigaChat\",\n","    verify_ssl_certs=False,\n",")\n","\n","class ChatState(TypedDict):\n","    messages: Annotated[Sequence, add_messages]\n","\n","prompt = ChatPromptTemplate.from_messages([\n","    (\"system\", SYSTEM_PROMPT),\n","    MessagesPlaceholder(variable_name=\"messages\"),\n","])\n","\n","def call_model(state: ChatState):\n","    chain = prompt | model\n","    response = chain.invoke(state)\n","    return {\"messages\": [response]}\n","\n","workflow = StateGraph(state_schema=ChatState)\n","workflow.add_node(\"model\", call_model)\n","workflow.add_edge(START, \"model\")\n","\n","memory = MemorySaver()\n","app = workflow.compile(checkpointer=memory)\n","\n","async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):\n","    await update.message.reply_text(\n","        \"–ü—Ä–∏–≤–µ—Ç! –ú–µ–Ω—è –∑–æ–≤—É—Ç Lumen. –Ø –ø–æ–º–æ–≥—É —Ç–µ–±–µ —Å–æ—Å—Ç–∞–≤–∏—Ç—å –ø–ª–∞–Ω –æ–±—É—á–µ–Ω–∏—è üìö\\n\"\n","        \"–ù–∞–ø–∏—à–∏, —á—Ç–æ —Ö–æ—á–µ—à—å –∏–∑—É—á–∏—Ç—å –∏ –∑–∞ –∫–∞–∫–æ–µ –≤—Ä–µ–º—è.\"\n","    )\n","\n","async def clear(update: Update, context: ContextTypes.DEFAULT_TYPE):\n","    user_id = str(update.effective_user.id)\n","    config = {\"configurable\": {\"thread_id\": user_id}}\n","    await app.aupdate_state(config, {\"messages\": []})\n","    await update.message.reply_text(\"–ü–∞–º—è—Ç—å –æ—á–∏—â–µ–Ω–∞!\")\n","\n","async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):\n","    user_id = str(update.effective_user.id)\n","    text = (update.message.text or \"\").strip()\n","    config = {\"configurable\": {\"thread_id\": user_id}}\n","\n","    thinking_msg = await update.message.reply_text(\"–ü–æ–∂–∞–ª—É–π—Å—Ç–∞ –ø–æ–¥–æ–∂–¥–∏—Ç–µ... ‚è≥\")\n","\n","    try:\n","        try:\n","            output = await asyncio.wait_for(\n","                app.ainvoke({\"messages\": [HumanMessage(content=text)]}, config),\n","                timeout=90.0,\n","            )\n","        except asyncio.TimeoutError:\n","            await thinking_msg.edit_text(\"–°–ª–∏—à–∫–æ–º –¥–æ–ª–≥–æ –¥—É–º–∞—é... –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —É—Ç–æ—á–Ω–∏—Ç—å –∑–∞–ø—Ä–æ—Å.\")\n","            return\n","\n","        plan_text = output[\"messages\"][-1].content\n","\n","        try:\n","            df = parse_markdown_table_to_df(plan_text)\n","            excel_bytes = df_to_excel_bytes(df)\n","            await thinking_msg.delete()\n","            await update.message.reply_document(\n","                document=InputFile(excel_bytes, filename=\"plan.xlsx\"),\n","                caption=\"–í–∞—à —É—á–µ–±–Ω—ã–π –ø–ª–∞–Ω –≤ Excel\",\n","            )\n","        except Exception:\n","            logging.exception(\"–û—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ –≤ Excel\")\n","            await thinking_msg.edit_text(plan_text[:4000])\n","\n","    except Exception:\n","        logging.exception(f\"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞ –æ—Ç {user_id}\")\n","        try:\n","            await thinking_msg.edit_text(\"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –≤–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.\")\n","        except Exception:\n","            await update.message.reply_text(\"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –≤–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞.\")\n","\n","async def main():\n","    application = Application.builder().token(TELEGRAM_BOT_TOKEN).build()\n","    application.add_handler(CommandHandler(\"start\", start))\n","    application.add_handler(CommandHandler(\"clear\", clear))\n","    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))\n","\n","    print(\"‚úÖ –ë–æ—Ç –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è... –û—Ç–∫—Ä–æ–π—Ç–µ Telegram –∏ –Ω–∞–ø–∏—à–∏—Ç–µ –µ–º—É.\")\n","    await application.initialize()\n","    await application.start()\n","    await application.updater.start_polling()\n","    print(\"‚úÖ –ë–æ—Ç –∑–∞–ø—É—â–µ–Ω –∏ —Å–ª—É—à–∞–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏—è\")\n","\n","# –í Colab —É–¥–æ–±–Ω–µ–µ –∑–∞–ø—É—Å–∫–∞—Ç—å —Ç–∞–∫:\n","loop = asyncio.get_event_loop()\n","if loop.is_running():\n","    # –¥–ª—è Colab / Jupyter\n","    import nest_asyncio\n","    nest_asyncio.apply()\n","    asyncio.create_task(main())\n","else:\n","    asyncio.run(main())\n"],"metadata":{"id":"pDDWg42Njlxq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Lumen03\n","*  –ó–¥–µ—Å—å —è –ø–æ–ø—ã—Ç–∞–ª—Å—è —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –µ–º–±–µ–¥–¥–∏–Ω–≥ –∏ RAG.–í—Ä–æ–¥–µ –æ–Ω —Ä–∞–±–æ—á–∏–π, –ø—Ä–∞–≤–¥–∞ —Ç—É–ø–∏—Ç –∏ –ø–æ—Å—Ç–æ—è–Ω–Ω–æ –≤—ã–¥–∞–µ—Ç excel —Ç–∞–±–ª–∏—Ü—É.\n","*  –í–æ–æ–±—â–µ, –±—ã–ª–æ –±—ã –Ω–µ–ø–ª–æ—Ö–æ, –µ—Å–ª–∏ –±—ã –∫—Ç–æ-—Ç–æ —Å–æ–±—Ä–∞–ª —Ö–æ—Ä–æ—à–∏–µ —Ä–µ—Å—É—Ä—Å—ã –¥–ª—è –∏–∑—É—á–µ–Ω–∏—è —á–µ–≥–æ-—Ç–æ –≤ IT(–ª—é–±–∞—è —Å—Ñ–µ—Ä–∞ –≤ IT). –ë—ã–ª–æ –±—ã –µ—â–µ –∫—Ä—É—Ç–æ, –µ—Å–ª–∏ –±—ã –±—ã–ª–∏ pdf - —Ä–µ—Å—É—Ä—Å—ã (–∏–Ω—Ç–µ—Ä–Ω–µ—Ç-–∫–Ω–∏–≥–∏ –∏ —Ç–æ–º—É –ø–æ–¥–æ–±–Ω–æ–µ). –ï—Å–ª–∏ –∑–Ω–∞–µ—Ç–µ - —Å–∫–∏–¥—ã–≤–∞–π—Ç–µ.\n","*  –ù–∞ –¥–∞–Ω–Ω—ã–π –º–æ–º–µ–Ω—Ç, —ç—Ç–æ —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –∫–æ–¥"],"metadata":{"id":"pfUcIsCHxwep"}},{"cell_type":"code","source":["!pip install -qU langchain-text-splitters\n","!pip install -qU langchain-community faiss-cpu\n","!pip install -qU sentence-transformers\n","\n"],"metadata":{"id":"hzC2-R8E4sp6","executionInfo":{"status":"ok","timestamp":1765114527800,"user_tz":-180,"elapsed":39103,"user":{"displayName":"–ê—Ä—Ç—ë–º –ü–æ–ø–æ–≤","userId":"14233710488033869358"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"1adbb462-ddb4-49d1-a6ba-cc488b73bed4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m58.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\n","google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n","google-genai 1.52.0 requires httpx<1.0.0,>=0.28.1, but you have httpx 0.26.0 which is incompatible.\n","firebase-admin 6.9.0 requires httpx[http2]==0.28.1, but you have httpx 0.26.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"code","source":["import os\n","import asyncio\n","import logging\n","import re\n","from io import BytesIO\n","from typing import Sequence\n","\n","import pandas as pd\n","from typing_extensions import Annotated, TypedDict\n","\n","from telegram import Update, InputFile\n","from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes\n","\n","from langchain_gigachat.chat_models import GigaChat\n","from langchain_community.embeddings import HuggingFaceEmbeddings\n","from langchain_core.messages import HumanMessage, BaseMessage\n","from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n","from langchain_core.documents import Document\n","\n","from langgraph.checkpoint.memory import MemorySaver\n","from langgraph.graph import START, END, StateGraph\n","from langgraph.graph.message import add_messages\n","\n","from langchain_text_splitters import RecursiveCharacterTextSplitter\n","from langchain_community.vectorstores import FAISS\n","\n","# --------------------------------------------------------------------\n","# 0. –ë–∞–∑–æ–≤–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è\n","# --------------------------------------------------------------------\n","logging.basicConfig(\n","    format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\",\n","    level=logging.INFO,\n",")\n","\n","# --------------------------------------------------------------------\n","# 1. –ù–∞—Å—Ç—Ä–æ–π–∫–∏: —á–∏—Ç–∞–µ–º —Ç–æ–∫–µ–Ω—ã –∏–∑ –æ–∫—Ä—É–∂–µ–Ω–∏—è\n","# --------------------------------------------------------------------\n","TELEGRAM_BOT_TOKEN = os.environ.get(\"TELEGRAM_BOT_TOKEN\")\n","GIGACHAT_CREDENTIALS = os.environ.get(\"GIGACHAT_CREDENTIALS\")\n","\n","if not TELEGRAM_BOT_TOKEN:\n","    raise RuntimeError(\"–ù–µ –∑–∞–¥–∞–Ω TELEGRAM_BOT_TOKEN –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è\")\n","\n","if not GIGACHAT_CREDENTIALS:\n","    raise RuntimeError(\"–ù–µ –∑–∞–¥–∞–Ω GIGACHAT_CREDENTIALS –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è\")\n","\n","# --------------------------------------------------------------------\n","# 2. IT-—Ä–µ—Å—É—Ä—Å—ã –¥–ª—è –º–∏–Ω–∏-RAG\n","# --------------------------------------------------------------------\n","IT_RESOURCES = [\n","    {\n","        \"topic\": \"python_beginner\",\n","        \"title\": \"MIT OCW: Introduction to Computer Science and Programming in Python\",\n","        \"url\": \"https://ocw.mit.edu/courses/6-0001-introduction-to-computer-science-and-programming-in-python-fall-2016/\",\n","        \"lang\": \"EN\",\n","        \"level\": \"beginner\",\n","        \"description\": \"–í–≤–æ–¥–Ω—ã–π –∫—É—Ä—Å –ø–æ –æ—Å–Ω–æ–≤–∞–º –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è –∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–∫–∏ –Ω–∞ Python.\"\n","    },\n","    {\n","        \"topic\": \"cs_core\",\n","        \"title\": \"MIT OCW: Introductory Programming Collection\",\n","        \"url\": \"https://ocw.mit.edu/collections/introductory-programming/\",\n","        \"lang\": \"EN\",\n","        \"level\": \"intermediate\",\n","        \"description\": \"–ü–æ–¥–±–æ—Ä–∫–∞ –±–∞–∑–æ–≤—ã—Ö –∫—É—Ä—Å–æ–≤ –ø–æ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—é –∏ –∫–æ–º–ø—å—é—Ç–µ—Ä–Ω—ã–º –Ω–∞—É–∫–∞–º.\"\n","    },\n","    {\n","        \"topic\": \"cs_many_courses\",\n","        \"title\": \"500+ Free Computer Science Courses\",\n","        \"url\": \"https://dev.to/manocormen/500-free-computer-science-online-courses-from-the-world-s-top-cs-universities-3pg5\",\n","        \"lang\": \"EN\",\n","        \"level\": \"mixed\",\n","        \"description\": \"–ë–æ–ª—å—à–∞—è –∫–æ–ª–ª–µ–∫—Ü–∏—è –±–µ—Å–ø–ª–∞—Ç–Ω—ã—Ö –æ–Ω–ª–∞–π–Ω-–∫—É—Ä—Å–æ–≤ –ø–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–∫–µ –æ—Ç –≤–µ–¥—É—â–∏—Ö –≤—É–∑–æ–≤.\"\n","    },\n","    {\n","        \"topic\": \"cs_1200_courses\",\n","        \"title\": \"1200 Free Computer Science Courses\",\n","        \"url\": \"https://www.freecodecamp.org/news/free-courses-top-cs-universities/\",\n","        \"lang\": \"EN\",\n","        \"level\": \"mixed\",\n","        \"description\": \"–°–ø–∏—Å–æ–∫ –±–µ—Å–ø–ª–∞—Ç–Ω—ã—Ö CS-–∫—É—Ä—Å–æ–≤ –æ—Ç —Ç–æ–ø–æ–≤—ã—Ö —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç–æ–≤.\"\n","    },\n","    {\n","        \"topic\": \"python_ru\",\n","        \"title\": \"–ö—É—Ä—Å: –ü—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –≤—Å–µ—Ö (Python, RU-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å)\",\n","        \"url\": \"https://www.coursera.org/learn/python-ru\",\n","        \"lang\": \"RU\",\n","        \"level\": \"beginner\",\n","        \"description\": \"–ù–∞—á–∞–ª—å–Ω—ã–π –∫—É—Ä—Å –ø–æ Python —Å —Ä—É—Å—Å–∫–æ—è–∑—ã—á–Ω—ã–º –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–æ–º.\"\n","    },\n","    {\n","        \"topic\": \"it_ru_platform\",\n","        \"title\": \"Stepik ‚Äì IT-–∫—É—Ä—Å—ã\",\n","        \"url\": \"https://stepik.org/catalog/search?tag=programming\",\n","        \"lang\": \"RU\",\n","        \"level\": \"mixed\",\n","        \"description\": \"–ö–∞—Ç–∞–ª–æ–≥ –∫—É—Ä—Å–æ–≤ –ø–æ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—é –∏ –¥—Ä—É–≥–∏–º IT-–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è–º.\"\n","    },\n","    {\n","    \"topic\": \"cs_ossu_path\",\n","    \"title\": \"OSSU: Computer Science Curriculum\",\n","    \"url\": \"https://github.com/ossu/computer-science\",\n","    \"lang\": \"EN\",\n","    \"level\": \"mixed\",\n","    \"description\": \"–ü–æ–ª–Ω–∞—è –¥–æ—Ä–æ–∂–Ω–∞—è –∫–∞—Ä—Ç–∞ —Å–∞–º–æ–æ–±—É—á–µ–Ω–∏—è –∫–æ–º–ø—å—é—Ç–µ—Ä–Ω—ã–º –Ω–∞—É–∫–∞–º –∏–∑ –±–µ—Å–ø–ª–∞—Ç–Ω—ã—Ö –æ–Ω–ª–∞–π–Ω‚Äë–∫—É—Ä—Å–æ–≤ –≤–µ–¥—É—â–∏—Ö —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç–æ–≤.\"\n","  },\n","  {\n","      \"topic\": \"web_fullstack_en\",\n","      \"title\": \"freeCodeCamp: Full Stack Web Development\",\n","      \"url\": \"https://www.freecodecamp.org\",\n","     \"lang\": \"EN\",\n","      \"level\": \"beginner\",\n","      \"description\": \"–ë–µ—Å–ø–ª–∞—Ç–Ω–∞—è –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∞—è –ø—Ä–æ–≥—Ä–∞–º–º–∞ –ø–æ –≤–µ–±‚Äë—Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ –∏ —Å–º–µ–∂–Ω—ã–º –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è–º —Å –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–º–∏ –∑–∞–¥–∞–Ω–∏—è–º–∏ –∏ –ø—Ä–æ–µ–∫—Ç–∞–º–∏.\"\n","  },\n","  {\n","      \"topic\": \"cs_university_free_en\",\n","      \"title\": \"Free University CS Courses (Open Culture / freeCodeCamp list)\",\n","      \"url\": \"https://www.freecodecamp.org/news/free-courses-top-cs-universities/\",\n","      \"lang\": \"EN\",\n","      \"level\": \"mixed\",\n","      \"description\": \"–ü–æ–¥–±–æ—Ä–∫–∞ —Å–æ—Ç–µ–Ω –±–µ—Å–ø–ª–∞—Ç–Ω—ã—Ö –∫—É—Ä—Å–æ–≤ –ø–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–∫–µ –æ—Ç —Ç–æ–ø‚Äë—É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç–æ–≤ –º–∏—Ä–∞.\"\n","  },\n","  {\n","     \"topic\": \"cs_harvard_free\",\n","     \"title\": \"Harvard Online: Free Courses (CS & Programming)\",\n","      \"url\": \"https://pll.harvard.edu/catalog/free\",\n","     \"lang\": \"EN\",\n","      \"level\": \"mixed\",\n","      \"description\": \"–ö–∞—Ç–∞–ª–æ–≥ –±–µ—Å–ø–ª–∞—Ç–Ω—ã—Ö –æ–Ω–ª–∞–π–Ω‚Äë–∫—É—Ä—Å–æ–≤ –ì–∞—Ä–≤–∞—Ä–¥–∞, –≤–∫–ª—é—á–∞—è –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø–æ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—é –∏ –∫–æ–º–ø—å—é—Ç–µ—Ä–Ω—ã–º –Ω–∞—É–∫–∞–º.\"\n","  },\n","  {\n","      \"topic\": \"cs_openlearn\",\n","      \"title\": \"OpenLearn: Digital & Computing\",\n","      \"url\": \"https://www.open.edu/openlearn/digital/free-courses\",\n","      \"lang\": \"EN\",\n","      \"level\": \"beginner\",\n","      \"description\": \"–ë–µ—Å–ø–ª–∞—Ç–Ω—ã–µ –∏–Ω—Ç—Ä–æ‚Äë–∫—É—Ä—Å—ã –ø–æ –∫–æ–º–ø—å—é—Ç–µ—Ä–∞–º, –ò–¢ –∏ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—é –æ—Ç Open University.\"\n","  },\n","  {\n","    \"topic\": \"ru_yandex_practicum_free\",\n","    \"title\": \"–Ø–Ω–¥–µ–∫—Å –ü—Ä–∞–∫—Ç–∏–∫—É–º: –±–µ—Å–ø–ª–∞—Ç–Ω—ã–µ –∫—É—Ä—Å—ã –ø–æ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—é\",\n","    \"url\": \"https://practicum.yandex.ru/catalog/programming/free/\",\n","    \"lang\": \"RU\",\n","    \"level\": \"beginner\",\n","    \"description\": \"–ü–æ–¥–±–æ—Ä–∫–∞ –±–µ—Å–ø–ª–∞—Ç–Ω—ã—Ö –≤–≤–æ–¥–Ω—ã—Ö –∫—É—Ä—Å–æ–≤ –ø–æ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—é –æ—Ç –Ø–Ω–¥–µ–∫—Å –ü—Ä–∞–∫—Ç–∏–∫—É–º–∞.\"\n","  },\n","  {\n","      \"topic\": \"ru_hexlet_free\",\n","      \"title\": \"Hexlet: –±–µ—Å–ø–ª–∞—Ç–Ω—ã–µ –∫—É—Ä—Å—ã –ø–æ IT‚Äë–ø—Ä–æ—Ñ–µ—Å—Å–∏—è–º\",\n","      \"url\": \"https://ru.hexlet.io/courses_free\",\n","      \"lang\": \"RU\",\n","      \"level\": \"beginner\",\n","      \"description\": \"–ë–µ—Å–ø–ª–∞—Ç–Ω—ã–µ —Å—Ç–∞—Ä—Ç–æ–≤—ã–µ –∫—É—Ä—Å—ã –ø–æ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—é –∏ —Å–º–µ–∂–Ω—ã–º IT‚Äë–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è–º —Å —É–ø–æ—Ä–æ–º –Ω–∞ –ø—Ä–∞–∫—Ç–∏–∫—É.\"\n","  },\n","  {\n","      \"topic\": \"ru_netology_free\",\n","      \"title\": \"–ù–µ—Ç–æ–ª–æ–≥–∏—è: –±–µ—Å–ø–ª–∞—Ç–Ω—ã–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã –ø–æ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ\",\n","      \"url\": \"https://netology.ru/free/development\",\n","      \"lang\": \"RU\",\n","      \"level\": \"beginner\",\n","      \"description\": \"–ë–µ—Å–ø–ª–∞—Ç–Ω—ã–µ –≤–≤–æ–¥–Ω—ã–µ –∫—É—Ä—Å—ã, –≤–µ–±–∏–Ω–∞—Ä—ã –∏ –º–∞—Ç–µ—Ä–∏–∞–ª—ã –ø–æ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ –∏ —Å–º–µ–∂–Ω—ã–º digital‚Äë–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è–º.\"\n","  },\n","  {\n","      \"topic\": \"ru_code_basics\",\n","      \"title\": \"CodeBasics: –æ—Å–Ω–æ–≤—ã –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è\",\n","      \"url\": \"https://code-basics.com/ru\",\n","      \"lang\": \"RU\",\n","      \"level\": \"beginner\",\n","      \"description\": \"–ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–µ —É–ø—Ä–∞–∂–Ω–µ–Ω–∏—è –ø–æ –æ—Å–Ω–æ–≤–∞–º —Ä–∞–∑–Ω—ã—Ö —è–∑—ã–∫–æ–≤ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è: Python, JavaScript, Go –∏ –¥—Ä.\"\n","  }\n","\n","]\n","\n","# --------------------------------------------------------------------\n","# 3. –ü–∞—Ä—Å–∏–Ω–≥ Markdown-—Ç–∞–±–ª–∏—Ü—ã –∏ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ Excel\n","# --------------------------------------------------------------------\n","def parse_markdown_table_to_df(text: str) -> pd.DataFrame:\n","    lines = text.strip().split('\\n')\n","    table_lines = []\n","    table_started = False\n","\n","    for line in lines:\n","        stripped = line.strip()\n","        if not table_started:\n","            if stripped.startswith('|') and len(stripped) > 3:\n","                table_started = True\n","            else:\n","                continue\n","        if stripped.startswith('|') and stripped.endswith('|'):\n","            cells = [cell.strip() for cell in stripped.split('|')[1:-1]]\n","            if any(cell for cell in cells):\n","                table_lines.append(cells)\n","        elif table_started:\n","            break\n","\n","    if len(table_lines) < 2:\n","        raise ValueError(\"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Å—Ç—Ä–æ–∫ –¥–ª—è —Ç–∞–±–ª–∏—Ü—ã (—Ç—Ä–µ–±—É–µ—Ç—Å—è –∑–∞–≥–æ–ª–æ–≤–æ–∫ + ‚â•1 —Å—Ç—Ä–æ–∫–∞)\")\n","\n","    headers = table_lines[0]\n","    data_rows = [\n","        row for row in table_lines[1:]\n","        if not all(re.fullmatch(r'-+', cell) for cell in row)\n","    ]\n","\n","    if not data_rows:\n","        raise ValueError(\"–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –≤ —Ç–∞–±–ª–∏—Ü–µ (—Ç–æ–ª—å–∫–æ –∑–∞–≥–æ–ª–æ–≤–æ–∫ –∏ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å)\")\n","\n","    return pd.DataFrame(data_rows, columns=headers)\n","\n","\n","def extract_links(text: str) -> list:\n","    LINK_PATTERN = r'\\[([^\\]]+)\\]\\(\\s*([^)]*?)\\s*\\)'\n","    matches = re.findall(LINK_PATTERN, text)\n","    links = [{\"title\": title.strip(), \"url\": url.strip()} for title, url in matches]\n","\n","    text_without_links = re.sub(LINK_PATTERN, '', text).strip()\n","    if text_without_links and not re.match(r'^[\\s,]*$', text_without_links):\n","        return [{\"context\": text_without_links, \"links\": links}] if links else [{\"raw\": text.strip()}]\n","\n","    return links if links else [{\"raw\": text.strip()}]\n","\n","\n","def df_to_excel_bytes(df: pd.DataFrame) -> BytesIO:\n","    try:\n","        df_out = df.copy()\n","\n","        # –°–ª—É–∂–µ–±–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞, –∫–∞–∫ –∏ —Ä–∞–Ω—å—à–µ\n","        if '–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ —Ä–µ—Å—É—Ä—Å—ã' in df_out.columns:\n","            df_out['resources'] = df_out['–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ —Ä–µ—Å—É—Ä—Å—ã'].apply(extract_links)\n","\n","        if '–ü—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å' in df_out.columns:\n","            def parse_duration(s):\n","                if not s:\n","                    return 1\n","                m = re.search(r'(\\d+)', s)\n","                return int(m.group(1)) if m else 1\n","\n","            df_out['duration_weeks'] = df_out['–ü—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å'].apply(parse_duration)\n","\n","        if '–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º–∞—è –¥–∞—Ç–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è' in df_out.columns:\n","            def parse_week_range(s):\n","                if not s:\n","                    return {\"start\": 1, \"end\": 1}\n","                m = re.search(r'(\\d+)(?:\\s*-\\s*(\\d+))?', s)\n","                if m:\n","                    start = int(m.group(1))\n","                    end = int(m.group(2)) if m.group(2) else start\n","                    return {\"start\": start, \"end\": end}\n","                return {\"raw\": s}\n","\n","            df_out['completion'] = df_out['–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º–∞—è –¥–∞—Ç–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è'].apply(parse_week_range)\n","\n","        # üëâ –û—Å—Ç–∞–≤–ª—è–µ–º –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —Ç–æ–ª—å–∫–æ –≤–∏–¥–∏–º—ã–µ —Å—Ç–æ–ª–±—Ü—ã\n","        hidden_cols = ['resources', 'duration_weeks', 'completion']\n","        visible_cols = [c for c in df_out.columns if c not in hidden_cols]\n","\n","        from openpyxl.utils import get_column_letter\n","\n","        output = BytesIO()\n","        with pd.ExcelWriter(output, engine='openpyxl') as writer:\n","            # –ü–∏—à–µ–º —Ç–æ–ª—å–∫–æ –≤–∏–¥–∏–º—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é –∫–æ–ª–æ–Ω–∫–∏\n","            df_out[visible_cols].to_excel(writer, sheet_name='–ü–ª–∞–Ω', index=False)\n","\n","            worksheet = writer.sheets['–ü–ª–∞–Ω']\n","            for i, col in enumerate(visible_cols, start=1):\n","                max_len = max(df_out[col].astype(str).map(len).max(), len(col)) + 2\n","                worksheet.column_dimensions[get_column_letter(i)].width = min(max_len, 50)\n","\n","        output.seek(0)\n","        return output\n","\n","    except Exception:\n","        logging.exception(\"–û—à–∏–±–∫–∞ –≤ df_to_excel_bytes\")\n","        raise\n","\n","\n","# --------------------------------------------------------------------\n","# 4. –ú–æ–¥–µ–ª—å GigaChat (—á–∞—Ç) –∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏\n","# --------------------------------------------------------------------\n","model = GigaChat(\n","    credentials=GIGACHAT_CREDENTIALS,\n","    scope=\"GIGACHAT_API_PERS\",\n","    model=\"GigaChat-Max\",\n","    verify_ssl_certs=False,\n",")\n","\n","embeddings = HuggingFaceEmbeddings(\n","    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n","    model_kwargs={\"device\": \"cpu\"},\n",")\n","\n","# --------------------------------------------------------------------\n","# 5. –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞ –ø–æ IT_RESOURCES\n","# --------------------------------------------------------------------\n","docs = []\n","for res in IT_RESOURCES:\n","    content = (\n","        f\"{res['title']}. {res['description']} \"\n","        f\"–Ø–∑—ã–∫: {res['lang']}. –£—Ä–æ–≤–µ–Ω—å: {res['level']}.\"\n","    )\n","    docs.append(Document(page_content=content, metadata=res))\n","\n","text_splitter = RecursiveCharacterTextSplitter(\n","    chunk_size=300,\n","    chunk_overlap=50,\n",")\n","doc_splits = text_splitter.split_documents(docs)\n","\n","vectorstore = FAISS.from_documents(doc_splits, embeddings)\n","retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n","\n","# --------------------------------------------------------------------\n","# 6. –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è RAG-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ –ø–æ –æ–±—É—á–µ–Ω–∏—é IT\n","# --------------------------------------------------------------------\n","RAG_SYSTEM_PROMPT = (\n","    \"–¢—ã ‚Äî –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫ –ø–æ –æ–±—É—á–µ–Ω–∏—é –≤ —Å—Ñ–µ—Ä–µ IT. \"\n","    \"–¢–≤–æ—è –æ—Å–Ω–æ–≤–Ω–∞—è –∑–∞–¥–∞—á–∞ ‚Äî —Å–æ—Å—Ç–∞–≤–ª—è—Ç—å –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —É—á–µ–±–Ω—ã–µ –ø–ª–∞–Ω—ã –≤ –≤–∏–¥–µ \"\n","    \"—Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–π Markdown-—Ç–∞–±–ª–∏—Ü—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, \"\n","    \"–ò–°–ü–û–õ–¨–ó–£–Ø –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç —Ä–µ—Å—É—Ä—Å–æ–≤ (–∫—É—Ä—Å—ã, –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã, –ø–æ–¥–±–æ—Ä–∫–∏).\\n\\n\"\n","    \"–ö–æ–Ω—Ç–µ–∫—Å—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö IT-—Ä–µ—Å—É—Ä—Å–æ–≤:\\n{context}\\n\\n\"\n","    \"–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ —Ç–∞–±–ª–∏—Ü–µ:\\n\"\n","    \"1. –¢–∞–±–ª–∏—Ü–∞ –î–û–õ–ñ–ù–ê –Ω–∞—á–∏–Ω–∞—Ç—å—Å—è —Å–æ —Å—Ç—Ä–æ–∫–∏ '### –£—á–µ–±–Ω—ã–π –ø–ª–∞–Ω' –∏ —Å–æ–¥–µ—Ä–∂–∞—Ç—å –†–û–í–ù–û 7 –∫–æ–ª–æ–Ω–æ–∫ –≤ —ç—Ç–æ–º –ø–æ—Ä—è–¥–∫–µ:\\n\"\n","    \"   ‚Ññ | –¢–µ–º–∞/–ú–æ–¥—É–ª—å | –¶–µ–ª—å –∏–∑—É—á–µ–Ω–∏—è | –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ —Ä–µ—Å—É—Ä—Å—ã | –§–æ—Ä–º–∞—Ç –∑–∞–Ω—è—Ç–∏–π | –ü—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å | –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º–∞—è –¥–∞—Ç–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è\\n\"\n","    \"2. –í –∫–æ–ª–æ–Ω–∫–µ '–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ —Ä–µ—Å—É—Ä—Å—ã' –∏—Å–ø–æ–ª—å–∑—É–π –¢–û–õ–¨–ö–û —Ñ–æ—Ä–º–∞—Ç —Å—Å—ã–ª–æ–∫ Markdown: [–ù–∞–∑–≤–∞–Ω–∏–µ](URL).\\n\"\n","    \"   –ï—Å–ª–∏ —Ä–µ—Å—É—Ä—Å–æ–≤ –Ω–µ—Å–∫–æ–ª—å–∫–æ ‚Äî –ø–µ—Ä–µ—á–∏—Å–ª–∏ —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é: [A](url1), [B](url2).\\n\"\n","    \"3. –í –∫–æ–ª–æ–Ω–∫–µ '–ü—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å' —É–∫–∞–∑—ã–≤–∞–π –¢–û–õ–¨–ö–û —á–∏—Å–ª–æ –∏ –µ–¥–∏–Ω–∏—Ü—É: '1 –Ω–µ–¥–µ–ª—è', '2 –Ω–µ–¥–µ–ª–∏', '3 –Ω–µ–¥–µ–ª–∏'.\\n\"\n","    \"4. –í –∫–æ–ª–æ–Ω–∫–µ '–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º–∞—è –¥–∞—Ç–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è' –∏—Å–ø–æ–ª—å–∑—É–π —Ñ–æ—Ä–º–∞—Ç: '–Ω–µ–¥–µ–ª—è 1', '–Ω–µ–¥–µ–ª–∏ 2-3', '–Ω–µ–¥–µ–ª–∏ 8-9'.\\n\"\n","    \"5. –ü–µ—Ä–µ–¥ —Ç–µ–º –∫–∞–∫ —Å—Ç—Ä–æ–∏—Ç—å –ø–ª–∞–Ω, –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –∑–∞–¥–∞–π —É—Ç–æ—á–Ω—è—é—â–∏–µ –≤–æ–ø—Ä–æ—Å—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é.\\n\"\n","    \"6. –ü–æ–¥–±–∏—Ä–∞—è —Ä–µ—Å—É—Ä—Å—ã, –≤ –ø–µ—Ä–≤—É—é –æ—á–µ—Ä–µ–¥—å –∏—Å–ø–æ–ª—å–∑—É–π —Ç–µ, —á—Ç–æ –µ—Å—Ç—å –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ.\"\n",")\n","\n","rag_prompt = ChatPromptTemplate.from_messages([\n","    (\"system\", RAG_SYSTEM_PROMPT),\n","    MessagesPlaceholder(variable_name=\"messages\"),\n","])\n","\n","# --------------------------------------------------------------------\n","# 7. –°–æ—Å—Ç–æ—è–Ω–∏–µ –¥–ª—è LangGraph –∏ —É–∑–ª—ã RAG-–≥—Ä–∞—Ñ–∞\n","# --------------------------------------------------------------------\n","class RAGState(TypedDict):\n","    messages: Annotated[Sequence[BaseMessage], add_messages]\n","    context: str\n","\n","def retrieve_node(state: RAGState) -> dict:\n","    last_human = None\n","    for m in reversed(state[\"messages\"]):\n","        if isinstance(m, HumanMessage):\n","            last_human = m\n","            break\n","    query = last_human.content if last_human else \"\"\n","    docs = retriever.invoke(query)\n","    context_text = \"\\n\\n\".join(d.page_content for d in docs)\n","    return {\"context\": context_text}\n","\n","def call_rag_model(state: RAGState) -> dict:\n","    chain = rag_prompt | model\n","    response = chain.invoke(state)\n","    return {\"messages\": [response]}\n","\n","# --------------------------------------------------------------------\n","# 8. –°–±–æ—Ä–∫–∞ RAG-–≥—Ä–∞—Ñ–∞ —Å –ø–∞–º—è—Ç—å—é\n","# --------------------------------------------------------------------\n","workflow = StateGraph(state_schema=RAGState)\n","workflow.add_node(\"retrieve\", retrieve_node)\n","workflow.add_node(\"model\", call_rag_model)\n","\n","workflow.add_edge(START, \"retrieve\")\n","workflow.add_edge(\"retrieve\", \"model\")\n","workflow.add_edge(\"model\", END)\n","\n","memory = MemorySaver()\n","app = workflow.compile(checkpointer=memory)\n","\n","# --------------------------------------------------------------------\n","# 9. Telegram-–æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏\n","# --------------------------------------------------------------------\n","async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):\n","    await update.message.reply_text(\n","        \"–ü—Ä–∏–≤–µ—Ç! –ú–µ–Ω—è –∑–æ–≤—É—Ç Lumen. –Ø –ø–æ–º–æ–≥—É —Ç–µ–±–µ —Å–æ—Å—Ç–∞–≤–∏—Ç—å IT-—É—á–µ–±–Ω—ã–π –ø–ª–∞–Ω üìö\\n\"\n","        \"–ù–∞–ø–∏—à–∏, —á—Ç–æ —Ö–æ—á–µ—à—å –∏–∑—É—á–∏—Ç—å –∏ –∑–∞ –∫–∞–∫–æ–µ –≤—Ä–µ–º—è.\"\n","    )\n","\n","async def clear(update: Update, context: ContextTypes.DEFAULT_TYPE):\n","    user_id = str(update.effective_user.id)\n","    config = {\"configurable\": {\"thread_id\": user_id}}\n","    await app.aupdate_state(config, {\"messages\": []})\n","    await update.message.reply_text(\"–ü–∞–º—è—Ç—å –æ—á–∏—â–µ–Ω–∞!\")\n","\n","async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):\n","    user_id = str(update.effective_user.id)\n","    text = (update.message.text or \"\").strip()\n","    config = {\"configurable\": {\"thread_id\": user_id}}\n","\n","    thinking_msg = await update.message.reply_text(\"–ü–æ–∂–∞–ª—É–π—Å—Ç–∞ –ø–æ–¥–æ–∂–¥–∏—Ç–µ... ‚è≥\")\n","\n","    try:\n","        # –û–¥–∏–Ω –≤—ã–∑–æ–≤ RAG-–≥—Ä–∞—Ñ–∞\n","        output = await asyncio.wait_for(\n","            app.ainvoke(\n","                {\"messages\": [HumanMessage(content=text)], \"context\": \"\"},\n","                config,\n","            ),\n","            timeout=90.0,\n","        )\n","\n","        plan_text = output[\"messages\"][-1].content\n","\n","        # –ü—ã—Ç–∞–µ–º—Å—è —Å–¥–µ–ª–∞—Ç—å Excel –∏–∑ –æ—Ç–≤–µ—Ç–∞\n","        try:\n","            df = parse_markdown_table_to_df(plan_text)\n","            excel_bytes = df_to_excel_bytes(df)\n","            await thinking_msg.delete()\n","            await update.message.reply_document(\n","                document=InputFile(excel_bytes, filename=\"plan.xlsx\"),\n","                caption=\"–í–∞—à —É—á–µ–±–Ω—ã–π –ø–ª–∞–Ω –≤ Excel\",\n","            )\n","        except Exception:\n","            logging.exception(\"–û—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ –≤ Excel\")\n","            await thinking_msg.edit_text(plan_text[:4000])\n","\n","    except Exception as e:\n","        import traceback\n","        err_text = \"\".join(traceback.format_exception_only(type(e), e))\n","        logging.exception(f\"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞ –æ—Ç {user_id}\")\n","        try:\n","            await thinking_msg.edit_text(\"–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞:\\n\" + err_text[:3500])\n","        except Exception:\n","            await update.message.reply_text(\"–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞:\\n\" + err_text[:3500])\n","\n","# --------------------------------------------------------------------\n","# 10. –ó–∞–ø—É—Å–∫ –±–æ—Ç–∞ (–∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω –ø–æ–¥ Colab / Jupyter)\n","# --------------------------------------------------------------------\n","async def main():\n","    application = Application.builder().token(TELEGRAM_BOT_TOKEN).build()\n","\n","    application.add_handler(CommandHandler(\"start\", start))\n","    application.add_handler(CommandHandler(\"clear\", clear))\n","    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))\n","\n","    print(\"‚úÖ –ë–æ—Ç –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è... –ù–∞–ø–∏—à–∏—Ç–µ –µ–º—É –≤ Telegram.\")\n","    await application.initialize()\n","    await application.start()\n","    await application.updater.start_polling()\n","    print(\"‚úÖ –ë–æ—Ç –∑–∞–ø—É—â–µ–Ω –∏ —Å–ª—É—à–∞–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏—è\")\n","\n","# –ó–∞–ø—É—Å–∫ —Å —É—á—ë—Ç–æ–º Colab / Jupyter\n","loop = asyncio.get_event_loop()\n","if loop.is_running():\n","    import nest_asyncio\n","    nest_asyncio.apply()\n","    asyncio.create_task(main())\n","else:\n","    asyncio.run(main())\n"],"metadata":{"id":"oj4SEu_nJePo"},"execution_count":null,"outputs":[]}]}